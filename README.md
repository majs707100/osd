#  딥러닝 기반 다차원 음성 인지 시스템 제안 

---

##  프로젝트 소개

본 프로젝트는 **시각/청각 장애인의 대화 불평등을 해소**하고, 딥러닝 기술을 활용하여 음성 데이터에서 **다 차원적인 맥락 정보**를 파악하는 시스템을 구축하고자 합니다.

대화는 음성적인 내용 이외에도 시각적인 표정, 몸짓이나 목소리의 높낮이 등의 어조와 같이 복합적인 요소를 통해서 맥락을 파악해야 하는 고차원적인 과정입니다. 이러한 핵심 요소를 인지하는 데 어려움이 있는 장애인들은 대화의 모든 맥락을 완벽하게 이해하기 어렵습니다.

* **예시:** 동일한 문장이라도 어조에 따라 의미가 이중적으로 이해될 수 있는데, 이 시스템은 단순한 음성 내용을 넘어 **화자의 성별, 실시간 감정 및 어조**와 같은 비언어적 단서를 제공함으로써, 대화의 맥락을 정확히 해석할 수 있도록 돕습니다.

---

## ⚙️ **주요 문제 및 해결 방안 (딥러닝 모델)**

본 프로젝트는 다음과 같은 3가지 주요 문제를 정의하고, 이에 대한 딥러닝 기반 해결 방안을 제안합니다.

| No. | 해결할 문제 | 해결 방안 | 활용 모델/기술 |
| :---: | :--- | :--- | :--- |
| **1** | **낮은 품질 및 잡음 문제** | 불필요한 잡음/침묵 제거 및 핵심 특징 추출 | **VAD** (Voice Activity Detection), **MFCC** (Mel-Frequency Cepstral Coefficients) |
| **2** | **여러 화자의 혼재 문제** | 화자 고유 특징 추출 및 동일 화자 그룹화/식별 | **TDNN** (Time Delay Neural Network), **x-vector 임베딩** |
| **3** | **추가적인 맥락 정보 부족** | 화자의 성별, 감정 및 어조와 같은 비언어적 단서 분석 | **CNN-LSTM** (Convolutional Neural Network - Long Short-Term Memory) |

### **시스템 개요 (흐름도)**

프로젝트의 전체 시스템 흐름은 네 가지 단계로 구성됩니다.

1.  **음성 전처리 및 특징 추출 (VAD / MFCC):** 잡음과 침묵을 제거하고 핵심 음향 특징을 추출합니다.
2.  **화자 벡터화 및 그룹화 (TDNN & x-vector):** 화자 고유의 특징을 추출하고 동일 화자를 그룹화하여 누가 말했는지를 식별합니다.
3.  **성별 및 감정 분석 (CNN-LSTM):** 개별 화자의 음성에 대해 성별 정보와 감정, 어조를 분석하여 추가적인 맥락을 추출합니다.
4.  **통합 정보 전달 (ASR/TTS API):** ASR(자동 음성 인식) API를 활용하여 대화 내용을 텍스트로 변환하고 성별/감정 등의 추가 정보를 합하여 TTS(Text-to-Speech) 출력을 합니다.

---

## ️ **향후 계획**

본 프로젝트의 성공적인 목표 달성을 위해 다음과 같은 후속 작업이 필요합니다.

* **실시간 처리 환경 구축:** 실제 대화 환경에 적용할 수 있도록 플랫폼을 구축하고, 음성 데이터의 **실시간 최적화**를 통해 딜레이를 최소화해야 할 것입니다.
* **사용자 피드백 수렴:** 시각/청각 장애인을 대상으로 **사용성 및 정보 전달 방식**에 대한 피드백을 수집하고 UI 등을 개선하여 대화 불평등 해소에 실질적으로 기여해야 할 것입니다.
